{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Data Project from Scratch This is an example project dedicated to demonstrating refactoring practices. In this space, you will find an in-depth description of ETL, installation instructions, answers to frequently asked questions, and more. Whether you are a collaborator or simply someone interested in the project, we hope you find this documentation useful. Additionally, this documentation can be integrated into Confluence or an internal intranet, facilitating access and collaboration for all team members. Sections Data Project from Scratch Sections Introduction Installation Guide Introduction The objective of this project is to demonstrate how refactoring techniques can be applied to improve code quality, optimize performance and make software more maintainable. Refactoring is essential for keeping code clean and understandable, allowing teams to maintain high development velocity over time. Prerequisites: Git for code versioning Pyenv for creating virtual environments Poetry for dependency management Pytest for unit and integration testing MKDocs for documentation and GitHub Pages to host it GitHub Actions for Continuous Integration Installation Guide Here, you will find detailed instructions on how to install and configure the project in your local environment. Following the instructions correctly ensures that you have a smooth experience when working on the project. Clone the repository git clone https://github.com/guimarczewski/DataProject.git cd DataProject Configure the correct Python version with pyenv pyenv install 3.11.3 pyenv local 3.11.3 Install project dependencies poetry install Activate the virtual environment poetry shell Run the tests task test Run the documentation task doc Run the pipeline task run","title":"Home"},{"location":"#data-project-from-scratch","text":"This is an example project dedicated to demonstrating refactoring practices. In this space, you will find an in-depth description of ETL, installation instructions, answers to frequently asked questions, and more. Whether you are a collaborator or simply someone interested in the project, we hope you find this documentation useful. Additionally, this documentation can be integrated into Confluence or an internal intranet, facilitating access and collaboration for all team members.","title":"Data Project from Scratch"},{"location":"#sections","text":"Data Project from Scratch Sections Introduction Installation Guide","title":"Sections"},{"location":"#introduction","text":"The objective of this project is to demonstrate how refactoring techniques can be applied to improve code quality, optimize performance and make software more maintainable. Refactoring is essential for keeping code clean and understandable, allowing teams to maintain high development velocity over time. Prerequisites: Git for code versioning Pyenv for creating virtual environments Poetry for dependency management Pytest for unit and integration testing MKDocs for documentation and GitHub Pages to host it GitHub Actions for Continuous Integration","title":"Introduction"},{"location":"#installation-guide","text":"Here, you will find detailed instructions on how to install and configure the project in your local environment. Following the instructions correctly ensures that you have a smooth experience when working on the project.","title":"Installation Guide"},{"location":"#clone-the-repository","text":"git clone https://github.com/guimarczewski/DataProject.git cd DataProject","title":"Clone the repository"},{"location":"#configure-the-correct-python-version-with-pyenv","text":"pyenv install 3.11.3 pyenv local 3.11.3","title":"Configure the correct Python version with pyenv"},{"location":"#install-project-dependencies","text":"poetry install","title":"Install project dependencies"},{"location":"#activate-the-virtual-environment","text":"poetry shell","title":"Activate the virtual environment"},{"location":"#run-the-tests","text":"task test","title":"Run the tests"},{"location":"#run-the-documentation","text":"task doc","title":"Run the documentation"},{"location":"#run-the-pipeline","text":"task run","title":"Run the pipeline"},{"location":"app/","text":"APP Documentation Below you will find details about the functions and modules of the project. Consolidator module extract def extract(input_folder: str) -> list: \"\"\" Function to extract data from Excel files. Args: input_folder (str): Path of folder containing Excel files. Returns: list: List containing pandas DataFrames. \"\"\" transform def transform(data: list) -> pd.DataFrame: \"\"\" Function to transform a list of DataFrames into a single consolidated DataFrame. Args: data (list): List containing DataFrames for consolidation. Returns: DataFrame: Consolidated DataFrame. \"\"\" load def load(df: pd.DataFrame, output_folder: str, filename: str) -> None: \"\"\" Function to save a DataFrame into an Excel file. Args: df (pd.DataFrame): DataFrame to be saved. output_folder (str): Directory where the file will be saved. filename (str): Excel file name. Returns: None \"\"\" consolidate_excels def consolidate_excels(input_folder: str, output_folder: str, filename: str) -> None: \"\"\" Function to consolidate multiple Excel files into a single file. Args: input_folder (str): Folder containing Excel files. output_folder (str): Folder where the consolidated file will be saved. filename (str): Name of the consolidated Excel file. Returns: None \"\"\"","title":"APP"},{"location":"app/#app-documentation","text":"Below you will find details about the functions and modules of the project.","title":"APP Documentation"},{"location":"app/#consolidator-module","text":"","title":"Consolidator module"},{"location":"app/#extract","text":"def extract(input_folder: str) -> list: \"\"\" Function to extract data from Excel files. Args: input_folder (str): Path of folder containing Excel files. Returns: list: List containing pandas DataFrames. \"\"\"","title":"extract"},{"location":"app/#transform","text":"def transform(data: list) -> pd.DataFrame: \"\"\" Function to transform a list of DataFrames into a single consolidated DataFrame. Args: data (list): List containing DataFrames for consolidation. Returns: DataFrame: Consolidated DataFrame. \"\"\"","title":"transform"},{"location":"app/#load","text":"def load(df: pd.DataFrame, output_folder: str, filename: str) -> None: \"\"\" Function to save a DataFrame into an Excel file. Args: df (pd.DataFrame): DataFrame to be saved. output_folder (str): Directory where the file will be saved. filename (str): Excel file name. Returns: None \"\"\"","title":"load"},{"location":"app/#consolidate_excels","text":"def consolidate_excels(input_folder: str, output_folder: str, filename: str) -> None: \"\"\" Function to consolidate multiple Excel files into a single file. Args: input_folder (str): Folder containing Excel files. output_folder (str): Folder where the consolidated file will be saved. filename (str): Name of the consolidated Excel file. Returns: None \"\"\"","title":"consolidate_excels"},{"location":"tests/","text":"Tests Documentation Below you will find details about the functions and modules of the project. Unitary Tests Create mock input folder with files def mock_input_folder(tmpdir): \"\"\" Fixture to create mock input folder with sample Excel files for testing. \"\"\" Create mock output folder @pytest.fixture def mock_output_folder(tmpdir): \"\"\" Fixture to create a mock output folder for testing. \"\"\" Extract test def test_extract(mock_input_folder): \"\"\" Test the extraction of data from the input folder. \"\"\" Extract test with no files def test_extract_no_files(tmpdir): \"\"\" Test extraction functionality with an empty input folder. \"\"\" Transform test def test_transform(): \"\"\" Test the transformation of dataframes. \"\"\" Transform test with empty list def test_transform_empty_list(): \"\"\" Test the transformation functionality with an empty list. \"\"\" No permission output folder def test_load_no_permission(tmpdir): \"\"\" Test the load functionality with a protected output folder. \"\"\" Load test def test_load(mock_output_folder): \"\"\" Test the load functionality. \"\"\" Integration Tests Test the complete pipeline def test_integration(): \"\"\" Integration test to check the full consolidate_excels functionality. This test simulates a real-world scenario by creating a temporary directory with a sample Excel file. The test then checks if the consolidation function works as expected. \"\"\"","title":"Tests"},{"location":"tests/#tests-documentation","text":"Below you will find details about the functions and modules of the project.","title":"Tests Documentation"},{"location":"tests/#unitary-tests","text":"","title":"Unitary Tests"},{"location":"tests/#create-mock-input-folder-with-files","text":"def mock_input_folder(tmpdir): \"\"\" Fixture to create mock input folder with sample Excel files for testing. \"\"\"","title":"Create mock input folder with files"},{"location":"tests/#create-mock-output-folder","text":"@pytest.fixture def mock_output_folder(tmpdir): \"\"\" Fixture to create a mock output folder for testing. \"\"\"","title":"Create mock output folder"},{"location":"tests/#extract-test","text":"def test_extract(mock_input_folder): \"\"\" Test the extraction of data from the input folder. \"\"\"","title":"Extract test"},{"location":"tests/#extract-test-with-no-files","text":"def test_extract_no_files(tmpdir): \"\"\" Test extraction functionality with an empty input folder. \"\"\"","title":"Extract test with no files"},{"location":"tests/#transform-test","text":"def test_transform(): \"\"\" Test the transformation of dataframes. \"\"\"","title":"Transform test"},{"location":"tests/#transform-test-with-empty-list","text":"def test_transform_empty_list(): \"\"\" Test the transformation functionality with an empty list. \"\"\"","title":"Transform test with empty list"},{"location":"tests/#no-permission-output-folder","text":"def test_load_no_permission(tmpdir): \"\"\" Test the load functionality with a protected output folder. \"\"\"","title":"No permission output folder"},{"location":"tests/#load-test","text":"def test_load(mock_output_folder): \"\"\" Test the load functionality. \"\"\"","title":"Load test"},{"location":"tests/#integration-tests","text":"","title":"Integration Tests"},{"location":"tests/#test-the-complete-pipeline","text":"def test_integration(): \"\"\" Integration test to check the full consolidate_excels functionality. This test simulates a real-world scenario by creating a temporary directory with a sample Excel file. The test then checks if the consolidation function works as expected. \"\"\"","title":"Test the complete pipeline"}]}